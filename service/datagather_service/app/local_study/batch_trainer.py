"""
ë°°ì¹˜ í•™ìŠµê¸° - RTX 4080 ìµœì í™”

ì—¬ëŸ¬ ì„¤ì •ìœ¼ë¡œ ì—°ì† í•™ìŠµì„ ì‹¤í–‰í•˜ì—¬ ìµœì ì˜ ê²°ê³¼ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
"""

import os
import sys
import time
import torch
from pathlib import Path
from typing import List, Dict, Optional
import logging
from datetime import datetime

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë¸ í´ë˜ìŠ¤ import
sys.path.append(str(Path(__file__).parent.parent.parent))
from app.local_study.main import LocalStudyManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RTX4080BatchTrainer:
    """RTX 4080 ìµœì í™” ë°°ì¹˜ í•™ìŠµê¸°"""
    
    def __init__(self):
        self.gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0
        logger.info(f"ğŸ–¥ï¸ GPU ë©”ëª¨ë¦¬: {self.gpu_memory_gb:.1f}GB")
        
        # RTX 4080 ìµœì í™” ì„¤ì •ë“¤
        self.training_configs = [
            # ì´ˆê³ ì† ëŒ€ìš©ëŸ‰ ë°°ì¹˜
            {"name": "âš¡ì´ˆê³ ì†", "epochs": 30, "batch_size": 256, "learning_rate": 1e-4},
            {"name": "ğŸš€ê³ ì†1", "epochs": 25, "batch_size": 192, "learning_rate": 8e-5},
            {"name": "ğŸš€ê³ ì†2", "epochs": 35, "batch_size": 128, "learning_rate": 5e-5},
            
            # ìµœì í™”ëœ í‘œì¤€ ì„¤ì •
            {"name": "ğŸ“Ší‘œì¤€1", "epochs": 40, "batch_size": 96, "learning_rate": 3e-5},
            {"name": "ğŸ“Ší‘œì¤€2", "epochs": 45, "batch_size": 80, "learning_rate": 2.5e-5},
            {"name": "ğŸ“Ší‘œì¤€3", "epochs": 50, "batch_size": 64, "learning_rate": 2e-5},
            
            # ì •ë°€ í•™ìŠµ
            {"name": "ğŸ¯ì •ë°€1", "epochs": 60, "batch_size": 48, "learning_rate": 1.5e-5},
            {"name": "ğŸ¯ì •ë°€2", "epochs": 70, "batch_size": 32, "learning_rate": 1e-5},
        ]
    
    def run_single_training(self, config: Dict) -> Dict:
        """ë‹¨ì¼ í•™ìŠµ ì‹¤í–‰"""
        try:
            logger.info(f"\n{'='*60}")
            logger.info(f"ğŸ¯ {config['name']} í•™ìŠµ ì‹œì‘")
            logger.info(f"   ğŸ“Š Epochs: {config['epochs']}")
            logger.info(f"   ğŸ“¦ Batch Size: {config['batch_size']}")
            logger.info(f"   ğŸ“š Learning Rate: {config['learning_rate']}")
            logger.info(f"{'='*60}")
            
            # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
            torch.cuda.empty_cache()
            
            # í•™ìŠµ ì‹œì‘ ì‹œê°„
            start_time = time.time()
            
            # í•™ìŠµ ê´€ë¦¬ì ì´ˆê¸°í™”
            study_manager = LocalStudyManager()
            
            # í•™ìŠµ ë°ì´í„° ì¤€ë¹„
            texts, labels = study_manager.prepare_training_data()
            
            # ëª¨ë¸ í•™ìŠµ
            training_result = study_manager.train_model(
                texts, 
                labels, 
                epochs=config['epochs'],
                batch_size=config['batch_size'],
                learning_rate=config['learning_rate']
            )
            
            # í•™ìŠµ ì™„ë£Œ ì‹œê°„
            end_time = time.time()
            duration = end_time - start_time
            
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
            test_result = None
            if texts:
                test_text = "Gasoline"  # ê³ ì • í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
                predictions = study_manager.predict_text(test_text)
                test_result = {
                    "test_text": test_text,
                    "predictions": predictions[:3]  # ìƒìœ„ 3ê°œë§Œ
                }
            
            result = {
                "name": config['name'],
                "config": config,
                "duration": duration,
                "training_result": training_result,
                "test_result": test_result,
                "timestamp": datetime.now().isoformat(),
                "status": "completed"
            }
            
            logger.info(f"âœ… {config['name']} ì™„ë£Œ: {duration:.1f}ì´ˆ ì†Œìš”")
            if test_result:
                logger.info(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼: {test_result['predictions'][0]['label']} ({test_result['predictions'][0]['similarity']:.1f}%)")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ {config['name']} ì‹¤íŒ¨: {e}")
            return {
                "name": config['name'],
                "config": config,
                "status": "failed",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def run_batch_training(self, target_iterations: int = 5, cooldown_seconds: int = 30):
        """ë°°ì¹˜ í•™ìŠµ ì‹¤í–‰"""
        logger.info(f"ğŸš€ RTX 4080 ë°°ì¹˜ í•™ìŠµ ì‹œì‘")
        logger.info(f"   ğŸ“‹ ì´ {len(self.training_configs)}ê°œ ì„¤ì •")
        logger.info(f"   ğŸ”„ {target_iterations}íšŒ ë°˜ë³µ")
        logger.info(f"   â±ï¸ ì¿¨ë‹¤ìš´: {cooldown_seconds}ì´ˆ")
        
        all_results = []
        
        for iteration in range(1, target_iterations + 1):
            logger.info(f"\nğŸ”„ ========== ë°˜ë³µ {iteration}/{target_iterations} ==========")
            
            iteration_results = []
            
            for i, config in enumerate(self.training_configs, 1):
                logger.info(f"\nğŸ“ [{iteration}-{i}/{len(self.training_configs)}] {config['name']} ì‹¤í–‰ ì¤‘...")
                
                # í•™ìŠµ ì‹¤í–‰
                result = self.run_single_training(config)
                iteration_results.append(result)
                all_results.append(result)
                
                # ì¤‘ê°„ ì¿¨ë‹¤ìš´ (ë§ˆì§€ë§‰ ì„¤ì •ì´ ì•„ë‹Œ ê²½ìš°)
                if i < len(self.training_configs):
                    logger.info(f"â¸ï¸ {cooldown_seconds//2}ì´ˆ ì¿¨ë‹¤ìš´...")
                    time.sleep(cooldown_seconds // 2)
            
            # ë°˜ë³µ ì™„ë£Œ í›„ ê²°ê³¼ ìš”ì•½
            successful = [r for r in iteration_results if r['status'] == 'completed']
            failed = [r for r in iteration_results if r['status'] == 'failed']
            
            logger.info(f"\nğŸ“Š ë°˜ë³µ {iteration} ê²°ê³¼:")
            logger.info(f"   âœ… ì„±ê³µ: {len(successful)}ê°œ")
            logger.info(f"   âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
            
            if successful:
                fastest = min(successful, key=lambda x: x['duration'])
                logger.info(f"   âš¡ ê°€ì¥ ë¹ ë¥¸ í•™ìŠµ: {fastest['name']} ({fastest['duration']:.1f}ì´ˆ)")
            
            # ë°˜ë³µ ê°„ ì¿¨ë‹¤ìš´
            if iteration < target_iterations:
                logger.info(f"â¸ï¸ ë°˜ë³µ ê°„ ì¿¨ë‹¤ìš´ {cooldown_seconds}ì´ˆ...")
                time.sleep(cooldown_seconds)
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        self.print_final_summary(all_results)
        return all_results
    
    def print_final_summary(self, results: List[Dict]):
        """ìµœì¢… ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        logger.info(f"\nğŸ‰ ========== ìµœì¢… ê²°ê³¼ ìš”ì•½ ==========")
        
        successful = [r for r in results if r['status'] == 'completed']
        failed = [r for r in results if r['status'] == 'failed']
        
        logger.info(f"ğŸ“Š ì „ì²´ í†µê³„:")
        logger.info(f"   âœ… ì„±ê³µ: {len(successful)}ê°œ")
        logger.info(f"   âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
        logger.info(f"   ğŸ“ˆ ì„±ê³µë¥ : {len(successful)/len(results)*100:.1f}%")
        
        if successful:
            # ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
            fastest = min(successful, key=lambda x: x['duration'])
            slowest = max(successful, key=lambda x: x['duration'])
            avg_duration = sum(r['duration'] for r in successful) / len(successful)
            
            logger.info(f"\nâš¡ ì„±ëŠ¥ ë¶„ì„:")
            logger.info(f"   ğŸƒ ê°€ì¥ ë¹ ë¥¸ í•™ìŠµ: {fastest['name']} ({fastest['duration']:.1f}ì´ˆ)")
            logger.info(f"   ğŸŒ ê°€ì¥ ëŠë¦° í•™ìŠµ: {slowest['name']} ({slowest['duration']:.1f}ì´ˆ)")
            logger.info(f"   ğŸ“Š í‰ê·  í•™ìŠµ ì‹œê°„: {avg_duration:.1f}ì´ˆ")
            
            # ì„¤ì •ë³„ ì„±ê³µë¥ 
            config_stats = {}
            for result in results:
                config_name = result['name']
                if config_name not in config_stats:
                    config_stats[config_name] = {'total': 0, 'success': 0}
                config_stats[config_name]['total'] += 1
                if result['status'] == 'completed':
                    config_stats[config_name]['success'] += 1
            
            logger.info(f"\nğŸ“‹ ì„¤ì •ë³„ ì„±ê³µë¥ :")
            for config_name, stats in config_stats.items():
                success_rate = stats['success'] / stats['total'] * 100
                logger.info(f"   {config_name}: {success_rate:.1f}% ({stats['success']}/{stats['total']})")
        
        logger.info(f"={'='*50}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # GPU í™•ì¸
        if not torch.cuda.is_available():
            logger.error("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"ğŸ–¥ï¸ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
        
        if "4080" not in gpu_name and gpu_memory < 15:
            logger.warning("âš ï¸ RTX 4080ì´ ì•„ë‹™ë‹ˆë‹¤. ì„¤ì •ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        # ë°°ì¹˜ í•™ìŠµê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        trainer = RTX4080BatchTrainer()
        results = trainer.run_batch_training(target_iterations=3, cooldown_seconds=20)
        
        logger.info("ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    main()
