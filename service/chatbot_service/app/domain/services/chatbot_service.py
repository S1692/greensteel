import asyncio
import uuid
import json
import os
from datetime import datetime
from typing import Dict, List, Optional, Any
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from app.common.settings import settings
from app.common.logger import chatbot_logger
from app.domain.schemas.chatbot import ChatMessage, ChatSession

class ChatbotService:
    """ì±—ë´‡ ì„œë¹„ìŠ¤ - RAG ê¸°ë°˜ìœ¼ë¡œ chatbot_training_data.jsonlë§Œì„ ì§€ì‹ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©"""
    
    def __init__(self):
        self.llm: Optional[ChatOpenAI] = None
        self.embeddings: Optional[OpenAIEmbeddings] = None
        self.vectorstore: Optional[Chroma] = None
        self.memory: Optional[ConversationBufferMemory] = None
        self.chat_chain: Optional[LLMChain] = None
        self.sessions: Dict[str, ChatSession] = {}
        self.knowledge_base_loaded = False
        
    async def initialize(self):
        """LangChainê³¼ OpenAI ì´ˆê¸°í™” ë° ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            if not settings.OPENAI_API_KEY:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # OpenAI LLM ì´ˆê¸°í™”
            self.llm = ChatOpenAI(
                api_key=settings.OPENAI_API_KEY,
                model=settings.OPENAI_MODEL,
                temperature=settings.OPENAI_TEMPERATURE,
                max_tokens=settings.OPENAI_MAX_TOKENS
            )
            
            # OpenAI Embeddings ì´ˆê¸°í™”
            self.embeddings = OpenAIEmbeddings(
                api_key=settings.OPENAI_API_KEY,
                model="text-embedding-3-small"
            )
            
            # ëŒ€í™” ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            
            # ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ
            await self._load_knowledge_base()
            
            chatbot_logger.info("ChatbotService ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            chatbot_logger.error(f"ChatbotService ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _load_knowledge_base(self):
        """chatbot_training_data.jsonl íŒŒì¼ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¡œ ë¡œë“œ"""
        try:
            # chatbot_training_data.jsonl íŒŒì¼ ê²½ë¡œ (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ)
            # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
            possible_paths = [
                os.path.join(os.path.dirname(__file__), "..", "..", "..", "..", "chatbot_training_data.jsonl"),
                os.path.join("/app", "chatbot_training_data.jsonl"),
                os.path.join(os.getcwd(), "chatbot_training_data.jsonl"),
                "chatbot_training_data.jsonl"
            ]
            
            training_data_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    training_data_path = path
                    break
            
            if not training_data_path:
                chatbot_logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë„í•œ ê²½ë¡œë“¤: {possible_paths}")
                return
            
            # JSONL íŒŒì¼ ì½ê¸°
            documents = []
            with open(training_data_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    
                    try:
                        data = json.loads(line)
                        if "messages" in data and len(data["messages"]) >= 2:
                            # ì‚¬ìš©ì ì§ˆë¬¸ê³¼ AI ë‹µë³€ ì¶”ì¶œ
                            user_msg = data["messages"][0]["content"]
                            ai_msg = data["messages"][1]["content"]
                            
                            # ë¬¸ì„œ ìƒì„± (ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê²°í•©)
                            combined_content = f"ì§ˆë¬¸: {user_msg}\n\në‹µë³€: {ai_msg}"
                            
                            doc = Document(
                                page_content=combined_content,
                                metadata={
                                    "user_question": user_msg,
                                    "ai_answer": ai_msg,
                                    "line_number": line_num,
                                    "source": "chatbot_training_data.jsonl"
                                }
                            )
                            documents.append(doc)
                            
                    except json.JSONDecodeError as e:
                        chatbot_logger.warning(f"JSON íŒŒì‹± ì˜¤ë¥˜ (ë¼ì¸ {line_num}): {e}")
                        continue
            
            if not documents:
                chatbot_logger.warning("ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                separators=["\n\n", "\n", ". ", " ", ""]
            )
            
            split_docs = text_splitter.split_documents(documents)
            
            # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
            self.vectorstore = Chroma.from_documents(
                documents=split_docs,
                embedding=self.embeddings,
                persist_directory=settings.CHROMA_PERSIST_DIRECTORY,
                collection_name=settings.CHROMA_COLLECTION_NAME
            )
            
            self.knowledge_base_loaded = True
            chatbot_logger.info(f"ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ, {len(split_docs)}ê°œ ì²­í¬")
            
        except Exception as e:
            chatbot_logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def _search_knowledge_base(self, query: str, top_k: int = 3) -> List[Document]:
        """ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰"""
        try:
            if not self.vectorstore or not self.knowledge_base_loaded:
                # ìë™ ì´ˆê¸°í™” ì‹œë„
                try:
                    await self.initialize()
                except Exception as e:
                    chatbot_logger.error(f"ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                    return []
            
            # ë²¡í„°ìŠ¤í† ì–´ê°€ ì—¬ì „íˆ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            if not self.vectorstore:
                chatbot_logger.warning("ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            docs = self.vectorstore.similarity_search(query, k=top_k)
            return docs
            
        except Exception as e:
            chatbot_logger.error(f"ì§€ì‹ ë² ì´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _get_system_prompt(self) -> str:
        """RAG ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """
ë‹¹ì‹ ì€ GreenSteel ESG í”Œë«í¼ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì¤‘ìš”í•œ ê·œì¹™:**
1. **ì˜¤ì§ ì œê³µëœ ì§€ì‹ ë² ì´ìŠ¤ì˜ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.**
2. **ì§€ì‹ ë² ì´ìŠ¤ì— ì—†ëŠ” ì •ë³´ì— ëŒ€í•´ì„œëŠ” "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ëŠ” ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ê³ , ìœ ì‚¬í•œ ê¸°ëŠ¥ì´ ìˆëŠ”ì§€ ì•ˆë‚´í•´ì£¼ì„¸ìš”.**
3. **ì ˆëŒ€ë¡œ ì§€ì‹ ë² ì´ìŠ¤ ì™¸ë¶€ì˜ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.**
4. **í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ë©°, ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”.**

**ë‹µë³€ í˜•ì‹:**
- ì§ˆë¬¸ì— ëŒ€í•œ ëª…í™•í•˜ê³  ì •í™•í•œ ë‹µë³€
- HTML ë§í¬ëŠ” ì‹¤ì œë¡œ ë Œë”ë§ë˜ì–´ì•¼ í•˜ë¯€ë¡œ ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ì§€ì‹ ë² ì´ìŠ¤ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ì•ŠìŒ

**HTML ë§í¬ ì˜ˆì‹œ:**
- ë°ì´í„° ì—…ë¡œë“œ: <a href="/data-upload" class="inline-flex items-center px-4 py-2 bg-blue-600 text-white text-sm font-medium rounded-md hover:bg-blue-700">ğŸ“Š ë°ì´í„° ì—…ë¡œë“œ í˜ì´ì§€ë¡œ ì´ë™</a>
- LCA ë¶„ì„: <a href="/lca" class="inline-flex items-center px-4 py-2 bg-green-600 text-white text-sm font-medium rounded-md hover:bg-green-700">ğŸŒ± LCA ë¶„ì„ í˜ì´ì§€ë¡œ ì´ë™</a>
- CBAM ê´€ë¦¬: <a href="/cbam" class="inline-flex items-center px-4 py-2 bg-orange-600 text-white text-sm font-medium rounded-md hover:bg-orange-700">ğŸŒ CBAM ê´€ë¦¬ í˜ì´ì§€ë¡œ ì´ë™</a>
- ì„¤ì •: <a href="/settings" class="inline-flex items-center px-4 py-2 bg-gray-600 text-white text-sm font-medium rounded-md hover:bg-gray-700">âš™ï¸ ì„¤ì • í˜ì´ì§€ë¡œ ì´ë™</a>
- í™ˆ: <a href="/" class="inline-flex items-center px-4 py-2 bg-indigo-600 text-white text-sm font-medium rounded-md hover:bg-indigo-700">ğŸ  í™ˆìœ¼ë¡œ ì´ë™</a>
"""

    async def process_message(self, message: str, context: str = "general", 
                           session_id: Optional[str] = None, 
                           user_id: Optional[str] = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° RAG ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±"""
        try:
            # ìë™ ì´ˆê¸°í™” (ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°)
            if not self.llm or not self.knowledge_base_loaded:
                await self.initialize()
            
            # ì„¸ì…˜ ê´€ë¦¬
            if not session_id:
                session_id = str(uuid.uuid4())
            
            if session_id not in self.sessions:
                self.sessions[session_id] = ChatSession(
                    session_id=session_id,
                    user_id=user_id,
                    created_at=datetime.utcnow(),
                    last_activity=datetime.utcnow(),
                    context=context
                )
            
            session = self.sessions[session_id]
            session.last_activity = datetime.utcnow()
            
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
            user_message = ChatMessage(
                id=str(uuid.uuid4()),
                role="user",
                content=message,
                timestamp=datetime.utcnow()
            )
            session.messages.append(user_message)
            
            # RAG ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±
            response = await self._generate_rag_response(message, context, session)
            
            # AI ì‘ë‹µ ì €ì¥
            ai_message = ChatMessage(
                id=str(uuid.uuid4()),
                role="assistant",
                content=response["response"],
                timestamp=datetime.utcnow(),
                metadata={
                    "model_used": settings.OPENAI_MODEL,
                    "tokens_used": response.get("tokens_used", 0),
                    "rag_used": True,
                    "sources": response.get("sources", [])
                }
            )
            session.messages.append(ai_message)
            
            return {
                "success": True,
                "message": "ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data": {
                    "response": response["response"],
                    "session_id": session_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "model_used": settings.OPENAI_MODEL,
                    "tokens_used": response.get("tokens_used", 0),
                    "context": context,
                    "rag_used": True,
                    "sources": response.get("sources", [])
                }
            }
            
        except Exception as e:
            chatbot_logger.error(f"ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "success": False,
                "message": f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "data": {}
            }
    
    async def _generate_rag_response(self, message: str, context: str, 
                                   session: ChatSession) -> Dict[str, Any]:
        """RAG ê¸°ë°˜ AI ì‘ë‹µ ìƒì„±"""
        try:
            # ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
            relevant_docs = await self._search_knowledge_base(message, top_k=3)
            
            if not relevant_docs:
                # ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
                return await self._generate_fallback_response(message)
            
            # ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
            context_docs = "\n\n".join([
                f"**ê´€ë ¨ ì •ë³´ {i+1}:**\n{doc.page_content}"
                for i, doc in enumerate(relevant_docs)
            ])
            
            # RAG í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            rag_prompt = f"""
{self._get_system_prompt()}

**ì°¸ê³ í•  ì§€ì‹ ë² ì´ìŠ¤ ì •ë³´:**
{context_docs}

**ì‚¬ìš©ì ì§ˆë¬¸:** {message}

**ì§€ì¹¨:** ìœ„ì˜ ì§€ì‹ ë² ì´ìŠ¤ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”. ì§€ì‹ ë² ì´ìŠ¤ì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”. ë§Œì•½ ì •ë³´ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ "í•´ë‹¹ ì •ë³´ëŠ” ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
"""
            
            # AI ì‘ë‹µ ìƒì„±
            messages = [
                SystemMessage(content=rag_prompt),
                HumanMessage(content=message)
            ]
            
            response = await self.llm.agenerate([messages])
            ai_response = response.generations[0][0].text.strip()
            
            # ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
            sources = [
                {
                    "content": doc.page_content[:200] + "...",
                    "metadata": doc.metadata
                }
                for doc in relevant_docs
            ]
            
            return {
                "response": ai_response,
                "tokens_used": response.llm_output.get("token_usage", {}).get("total_tokens", 0),
                "sources": sources
            }
            
        except Exception as e:
            chatbot_logger.error(f"RAG ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return await self._generate_fallback_response(message)
    
    async def _generate_fallback_response(self, message: str) -> Dict[str, Any]:
        """ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œì˜ fallback ì‘ë‹µ"""
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
            message_lower = message.lower()
            
            if "greensteel" in message_lower or "esg" in message_lower or "í”Œë«í¼" in message_lower:
                return {
                    "response": "GreenSteel ESG í”Œë«í¼ì€ ì² ê°• ì‚°ì—…ì˜ í™˜ê²½, ì‚¬íšŒ, ì§€ë°°êµ¬ì¡°(ESG) ì„±ê³¼ë¥¼ ê´€ë¦¬í•˜ê³  ê°œì„ í•˜ê¸° ìœ„í•œ ì¢…í•©ì ì¸ ë””ì§€í„¸ í”Œë«í¼ì…ë‹ˆë‹¤. í˜„ì¬ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "tokens_used": 0,
                    "sources": []
                }
            elif "cbam" in message_lower or "íƒ„ì†Œêµ­ê²½" in message_lower:
                return {
                    "response": "CBAM(Carbon Border Adjustment Mechanism)ì€ íƒ„ì†Œêµ­ê²½ì¡°ì •ë©”ì»¤ë‹ˆì¦˜ìœ¼ë¡œ, EUê°€ ë„ì…í•œ ì •ì±…ì…ë‹ˆë‹¤. í˜„ì¬ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "tokens_used": 0,
                    "sources": []
                }
            elif "lca" in message_lower or "ìƒëª…ì£¼ê¸°" in message_lower:
                return {
                    "response": "LCA(Life Cycle Assessment) ë¶„ì„ì€ ì œí’ˆì˜ ì „ì²´ ìƒëª…ì£¼ê¸° ë™ì•ˆ í™˜ê²½ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì²´ê³„ì ìœ¼ë¡œ í‰ê°€í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. í˜„ì¬ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ìƒì„¸í•œ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "tokens_used": 0,
                    "sources": []
                }
            else:
                return {
                    "response": "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                    "tokens_used": 0,
                    "sources": []
                }
                
        except Exception as e:
            chatbot_logger.error(f"Fallback ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "tokens_used": 0,
                "sources": []
            }
    
    async def get_chat_history(self, session_id: str, limit: int = 50) -> List[ChatMessage]:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            return session.messages[-limit:] if len(session.messages) > limit else session.messages
        return []
    
    async def clear_session(self, session_id: str) -> bool:
        """ì„¸ì…˜ ì´ˆê¸°í™”"""
        if session_id in self.sessions:
            del self.sessions[session_id]
            return True
        return False
    
    async def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
        if session_id in self.sessions:
            session = self.sessions[session_id]
            return {
                "session_id": session.session_id,
                "user_id": session.user_id,
                "created_at": session.created_at.isoformat(),
                "last_activity": session.last_activity.isoformat(),
                "message_count": len(session.messages),
                "context": session.context
            }
        return None
    
    async def get_knowledge_base_info(self) -> Dict[str, Any]:
        """ì§€ì‹ ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        return {
            "loaded": self.knowledge_base_loaded,
            "vectorstore_type": "Chroma" if self.vectorstore else None,
            "collection_name": settings.CHROMA_COLLECTION_NAME if self.vectorstore else None,
            "persist_directory": settings.CHROMA_PERSIST_DIRECTORY,
            "llm_initialized": self.llm is not None,
            "embeddings_initialized": self.embeddings is not None,
            "openai_api_key_set": bool(settings.OPENAI_API_KEY),
            "openai_api_key_length": len(settings.OPENAI_API_KEY) if settings.OPENAI_API_KEY else 0,
            "training_data_path": os.path.join(
                os.path.dirname(__file__), 
                "..", "..", "..", "..", 
                "chatbot_training_data.jsonl"
            ),
            "training_data_exists": os.path.exists(os.path.join(
                os.path.dirname(__file__), 
                "..", "..", "..", "..", 
                "chatbot_training_data.jsonl"
            ))
        }
