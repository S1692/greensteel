# ============================================================================
# ğŸš€ DataGather Service - Main Application
# ============================================================================

import asyncio
import logging
import os
import json
import re
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional, Dict, Any
import uvicorn
import httpx
import pandas as pd

from .infrastructure.database import database
from .infrastructure.config import settings

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format=settings.log_format
)
logger = logging.getLogger(__name__)

# í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ ì‹œìŠ¤í…œ
mapping_dictionary = {}

def load_training_dataset():
    """í•™ìŠµ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ ë§µí•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±"""
    global mapping_dictionary
    try:
        # í•™ìŠµ ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
        possible_paths = [
            os.path.join(os.path.dirname(__file__), "..", "í•™ìŠµ ë°ì´í„°ì…‹.xlsx"),  # app/../í•™ìŠµ ë°ì´í„°ì…‹.xlsx
            os.path.join(os.path.dirname(__file__), "..", "..", "í•™ìŠµ ë°ì´í„°ì…‹.xlsx"),  # app/../../í•™ìŠµ ë°ì´í„°ì…‹.xlsx
            "í•™ìŠµ ë°ì´í„°ì…‹.xlsx",  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
            os.path.join("/app", "í•™ìŠµ ë°ì´í„°ì…‹.xlsx"),  # Docker ì»¨í…Œì´ë„ˆ ë‚´ ì ˆëŒ€ ê²½ë¡œ
        ]
        
        dataset_path = None
        for path in possible_paths:
            if os.path.exists(path):
                dataset_path = path
                break
        
        if not dataset_path:
            logger.warning("âš ï¸ í•™ìŠµ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë§µí•‘ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            logger.warning(f"ì‹œë„í•œ ê²½ë¡œë“¤: {possible_paths}")
            return False
        
        # Excel íŒŒì¼ ì½ê¸°
        df = pd.read_excel(dataset_path)
        logger.info(f"ğŸ“Š í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ: {len(df)}í–‰")
        logger.info(f"ğŸ“Š ì»¬ëŸ¼: {list(df.columns)}")
        
        # Aì—´(Label)ê³¼ B~Kì—´(input_text1~10) ì‚¬ìš©
        mapping_dictionary = {}
        
        for index, row in df.iterrows():
            label = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""  # Aì—´ (Label)
            
            # B~Kì—´ (input_text1~10) ì²˜ë¦¬
            for col_idx in range(1, min(11, len(df.columns))):  # B~Kì—´ (1~10)
                input_text = str(row.iloc[col_idx]) if pd.notna(row.iloc[col_idx]) else ""
                if input_text and input_text.strip():
                    # ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ í‚¤ë¡œ, ë¼ë²¨ì„ ê°’ìœ¼ë¡œ ì €ì¥
                    mapping_dictionary[input_text.strip().lower()] = label.strip()
        
        logger.info(f"âœ… ë§µí•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± ì™„ë£Œ: {len(mapping_dictionary)}ê°œ í•­ëª©")
        logger.info(f"ğŸ“ ìƒ˜í”Œ ë§µí•‘: {dict(list(mapping_dictionary.items())[:5])}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def predict_material_with_mapping(input_text: str) -> tuple[str, float]:
    """í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ ë¶„ë¥˜"""
    try:
        logger.info(f"ğŸ” ë§µí•‘ ê¸°ë°˜ ë¶„ë¥˜ ì‹œì‘: '{input_text}'")
        
        if not mapping_dictionary:
            logger.warning("âš ï¸ ë§µí•‘ ë”•ì…”ë„ˆë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return input_text, 0.0
        
        # ì…ë ¥ í…ìŠ¤íŠ¸ ì •ê·œí™”
        normalized_input = input_text.strip().lower()
        
        # 1. ì •í™•í•œ ë§¤ì¹˜ í™•ì¸
        if normalized_input in mapping_dictionary:
            predicted_label = mapping_dictionary[normalized_input]
            logger.info(f"âœ… ì •í™•í•œ ë§¤ì¹˜ ë°œê²¬: '{input_text}' -> '{predicted_label}'")
            return predicted_label, 1.0
        
        # 2. ë¶€ë¶„ ë§¤ì¹˜ í™•ì¸ (í¬í•¨ ê´€ê³„)
        for key, value in mapping_dictionary.items():
            if key in normalized_input or normalized_input in key:
                logger.info(f"âœ… ë¶€ë¶„ ë§¤ì¹˜ ë°œê²¬: '{input_text}' -> '{value}' (í‚¤: '{key}')")
                return value, 0.8
        
        # 3. ì…ë ¥ê°’ì´ ì´ë¯¸ ë¼ë²¨ê³¼ ê°™ì€ì§€ í™•ì¸
        for key, value in mapping_dictionary.items():
            if value.lower() == normalized_input:
                logger.info(f"âœ… ì…ë ¥ê°’ì´ ë¼ë²¨ê³¼ ì¼ì¹˜: '{input_text}'")
                return input_text, 1.0
        
        # 4. ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        logger.info(f"âš ï¸ ë§¤ì¹˜ë˜ëŠ” ë¼ë²¨ì´ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜: '{input_text}'")
        return input_text, 0.0
        
    except Exception as e:
        logger.error(f"âŒ ë§µí•‘ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
        return input_text, 0.0

def generate_ai_recommendation(input_text: str) -> tuple[str, float]:
    """AI ì¶”ì²œ ë‹µë³€ ìƒì„± (í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ ì‚¬ìš©)"""
    try:
        # í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ ë¶„ë¥˜ ì‚¬ìš©
        return predict_material_with_mapping(input_text)
        
    except Exception as e:
        logger.error(f"âŒ AI ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return input_text, 0.0

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒëª…ì£¼ê¸° ê´€ë¦¬"""
    # ì‹œì‘ ì‹œ
    logger.info("ğŸš€ DataGather Serviceë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì„¤ì • ìœ íš¨ì„± ê²€ì¦
    if not settings.validate():
        raise RuntimeError("ì„¤ì • ìœ íš¨ì„± ê²€ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    await database.init_db()
    
    # í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ
    load_training_dataset()
    
    logger.info("âœ… DataGather Serviceê°€ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    yield
    
    # ì¢…ë£Œ ì‹œ
    logger.info("ğŸ›‘ DataGather Serviceë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤...")

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title=settings.app_name,
    version=settings.app_version,
    description="Data Collection & Processing Service - DDD Structure",
    lifespan=lifespan
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜
async def get_session() -> AsyncSession:
    """ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì˜ì¡´ì„±"""
    async for session in database.get_session():
        yield session

# ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜ ì œê±° - ì§ì ‘ ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ì‚¬ìš©

# ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    """ë£¨íŠ¸ ê²½ë¡œ"""
    return {
        "service": "DataGather Service",
        "version": "1.0.0",
        "description": "Data Collection & Processing Service - DDD Structure",
        "ai_config": {
            "model": "í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘",
            "mapping_entries": len(mapping_dictionary),
            "dataset_loaded": bool(mapping_dictionary)
        },
        "endpoints": {
            "health": "/health",
            "ai_process": "/ai-process",
            "ai_process_api": f"{settings.api_prefix}/datagather/ai-process",
            "ai_process_gateway": "/api/datagather/ai-process",
            "save_input_data": "/save-input-data",
            "save_output_data": "/save-output-data",
            "save_transport_data": "/save-transport-data",
            "save_process_data": "/save-process-data",
            "save_processed_data": "/save-processed-data",
            "get_input_data": "/api/datagather/input-data",
            "get_output_data": "/api/datagather/output-data",
            "get_transport_data": "/api/datagather/transport-data",
            "get_process_data": "/api/datagather/process-data",
            "delete_input_data": "/api/datagather/input-data/{id}",
            "delete_output_data": "/api/datagather/output-data/{id}",
            "delete_transport_data": "/api/datagather/transport-data/{id}",
            "delete_process_data": "/api/datagather/process-data/{id}",
            "classify_data": "/api/datagather/classify-data",
            "get_classified_data": "/api/datagather/classified-data",
            "documentation": "/docs"
        }
    }

# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
@app.get("/health")
async def health_check():
    """ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        db_healthy = await database.health_check()
        return {
            "status": "healthy" if db_healthy else "unhealthy",
            "service": settings.app_name,
            "version": settings.app_version,
            "database": "connected" if db_healthy else "disconnected"
        }
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={"status": "error", "error": str(e)}
        )

# Favicon ì—”ë“œí¬ì¸íŠ¸ (502 ì—ëŸ¬ ë°©ì§€)
@app.get("/favicon.ico")
async def favicon():
    """Favicon ìš”ì²­ ì²˜ë¦¬"""
    from fastapi.responses import Response
    return Response(status_code=204)

# AI ì²˜ë¦¬ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸
@app.post("/ai-process")
async def ai_process_data(data: Dict[str, Any]):
    """AI ë°ì´í„° ì²˜ë¦¬"""
    try:
        logger.info(f"ğŸ¤– AI ë°ì´í„° ì²˜ë¦¬ ìš”ì²­: {data.get('data_type', 'unknown')}")
        logger.info(f"ğŸ“Š ì „ì²´ ìš”ì²­ ë°ì´í„°: {data}")
        
        # ì…ë ¥ ë°ì´í„°ì—ì„œ ì²˜ë¦¬í•  ë°ì´í„° ì¶”ì¶œ
        input_data = data.get('data', [])
        logger.info(f"ğŸ“¥ ì…ë ¥ ë°ì´í„° ê°œìˆ˜: {len(input_data)}")
        logger.info(f"ğŸ“¥ ì…ë ¥ ë°ì´í„° ìƒ˜í”Œ: {input_data[:2] if input_data else 'ë¹ˆ ë°ì´í„°'}")
        
        # Hugging Face AI ì²˜ë¦¬
        processed_data = []
        
        for i, item in enumerate(input_data):
            logger.info(f"ğŸ”„ ì²˜ë¦¬ ì¤‘ì¸ í•­ëª© {i+1}: {item}")
            íˆ¬ì…ë¬¼ëª… = item.get('íˆ¬ì…ë¬¼ëª…', '')
            ê³µì • = item.get('ê³µì •', '')
            logger.info(f"   - íˆ¬ì…ë¬¼ëª…: '{íˆ¬ì…ë¬¼ëª…}', ê³µì •: '{ê³µì •}'")
            
            # í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ì„ ì‚¬ìš©í•˜ì—¬ AI ì¶”ì²œ ë‹µë³€ ìƒì„±
            try:
                ai_ì¶”ì²œë‹µë³€, actual_confidence = generate_ai_recommendation(íˆ¬ì…ë¬¼ëª…)
                logger.info(f"   - ë§µí•‘ ê¸°ë°˜ AI ë¶„ë¥˜ ê²°ê³¼: '{ai_ì¶”ì²œë‹µë³€}', ì‹ ë¢°ë„: {actual_confidence:.3f}")
                
            except Exception as e:
                logger.error(f"   - AI ë¶„ë¥˜ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
                ai_ì¶”ì²œë‹µë³€ = íˆ¬ì…ë¬¼ëª…  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©
                actual_confidence = 0.0
            
            # ê° í•­ëª©ì— AI ì²˜ë¦¬ ê²°ê³¼ ì¶”ê°€
            processed_item = {
                **item,
                "AIì¶”ì²œë‹µë³€": ai_ì¶”ì²œë‹µë³€,
                "ai_processed": True,
                "ai_model": "í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘",
                "ai_task": "mapping-classification",
                "classification": "processed",
                "confidence": actual_confidence,
                "processed_at": "2024-01-01T00:00:00Z"
            }
            processed_data.append(processed_item)
            logger.info(f"   âœ… í•­ëª© {i+1} ì²˜ë¦¬ ì™„ë£Œ")
        
        logger.info(f"ğŸ“Š ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ê°œìˆ˜: {len(processed_data)}")
        
        # AI ë¶„ë¥˜ ê²°ê³¼ë§Œ ë°˜í™˜
        ai_classification_results = []
        for item in processed_data:
            ai_result = {
                "íˆ¬ì…ë¬¼ëª…": item.get('íˆ¬ì…ë¬¼ëª…', ''),
                "ê³µì •": item.get('ê³µì •', ''),
                "AIë¶„ë¥˜ê²°ê³¼": item.get('AIì¶”ì²œë‹µë³€', ''),
                "ë¶„ë¥˜ì‹ ë¢°ë„": item.get('confidence', 0.0),
                "AIëª¨ë¸": item.get('ai_model', ''),
                "ì²˜ë¦¬ì‹œê°„": item.get('processed_at', '')
            }
            ai_classification_results.append(ai_result)
        
        response_data = {
            "success": True,
            "message": f"í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘ AI ë¶„ë¥˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ai_model": "í•™ìŠµ ë°ì´í„°ì…‹ ê¸°ë°˜ ë§µí•‘",
            "mapping_entries": len(mapping_dictionary),
            "ai_task": "mapping-classification",
            "total_classified": len(ai_classification_results),
            "ai_results": ai_classification_results  # AI ë¶„ë¥˜ ê²°ê³¼ë§Œ
        }
        
        logger.info("âœ… AI ë°ì´í„° ì²˜ë¦¬ ì„±ê³µ")
        logger.info(f"ğŸ“¤ ì‘ë‹µ ë°ì´í„°: {response_data}")
        return JSONResponse(
            status_code=200,
            content=response_data
        )
            
    except Exception as e:
        logger.error(f"âŒ AI ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "AI ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "data": []  # ì˜¤ë¥˜ ì‹œì—ë„ ë¹ˆ ë°°ì—´ ë°˜í™˜
            }
        )

@app.post(f"{settings.api_prefix}/datagather/ai-process")
async def ai_process_data_with_prefix(data: Dict[str, Any]):
    """AI ë°ì´í„° ì²˜ë¦¬ (API prefix í¬í•¨)"""
    return await ai_process_data(data)

# Gatewayì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ë¡œ (API prefix ì—†ì´)
@app.post("/api/datagather/ai-process")
async def ai_process_data_gateway(data: Dict[str, Any]):
    """AI ë°ì´í„° ì²˜ë¦¬ (Gateway ê²½ë¡œ)"""
    return await ai_process_data(data)

# íˆ¬ì…ë¬¼ ë°ì´í„° ì €ì¥ (ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸)
@app.post("/save-input-data")
async def save_input_data(data: Dict[str, Any]):
    """íˆ¬ì…ë¬¼ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        logger.info(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì €ì¥ ìš”ì²­: {data.get('filename', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        saved_count = 0
        with Session() as session:
            input_data_rows = data.get('data', [])
            
            for row in input_data_rows:
                try:
                    session.execute(text("""
                        INSERT INTO input_data 
                        (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°í’ˆëª…, ìƒì‚°ìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, íˆ¬ì…ì¼, ì¢…ë£Œì¼, 
                         ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, íˆ¬ì…ë¬¼_ë‹¨ìœ„, source_file, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                        VALUES (:ë¡œíŠ¸ë²ˆí˜¸, :ìƒì‚°í’ˆëª…, :ìƒì‚°ìˆ˜ëŸ‰, :ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, :íˆ¬ì…ì¼, :ì¢…ë£Œì¼,
                                :ê³µì •, :íˆ¬ì…ë¬¼ëª…, :ìˆ˜ëŸ‰, :íˆ¬ì…ë¬¼_ë‹¨ìœ„, :source_file, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                    """), {
                        'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                        'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                        'ìƒì‚°ìˆ˜ëŸ‰': float(row.get('ìƒì‚°ìˆ˜ëŸ‰', 0)) if row.get('ìƒì‚°ìˆ˜ëŸ‰') else 0,
                        'ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„': row.get('ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„', 't'),
                        'íˆ¬ì…ì¼': row.get('íˆ¬ì…ì¼'),
                        'ì¢…ë£Œì¼': row.get('ì¢…ë£Œì¼'),
                        'ê³µì •': row.get('ê³µì •', ''),
                        'íˆ¬ì…ë¬¼ëª…': row.get('íˆ¬ì…ë¬¼ëª…', ''),
                        'ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                        'íˆ¬ì…ë¬¼_ë‹¨ìœ„': row.get('íˆ¬ì…ë¬¼_ë‹¨ìœ„', 't'),
                        'source_file': data.get('filename', 'input_data'),
                        'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                        'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                    })
                    saved_count += 1
                except Exception as row_error:
                    logger.error(f"í–‰ ì €ì¥ ì‹¤íŒ¨: {row_error}, ë°ì´í„°: {row}")
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ê³„ì† ì§„í–‰
                    session.rollback()
                    continue
            
            session.commit()
        
        logger.info(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}í–‰ ì €ì¥ë¨")
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "message": f"íˆ¬ì…ë¬¼ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ({saved_count}í–‰)",
                "saved_count": saved_count,
                "filename": data.get('filename', ''),
                "total_rows": len(input_data_rows)
            }
        )
            
    except Exception as e:
        logger.error(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "íˆ¬ì…ë¬¼ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# íˆ¬ì…ë¬¼ ë°ì´í„° ì¡°íšŒ
@app.get("/api/datagather/input-data")
async def get_input_data():
    """íˆ¬ì…ë¬¼ ë°ì´í„° ì¡°íšŒ"""
    try:
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            result = session.execute(text("SELECT * FROM input_data ORDER BY created_at DESC"))
            rows = result.fetchall()
            
            data = []
            for row in rows:
                row_dict = dict(row._mapping)
                for key, value in row_dict.items():
                    if hasattr(value, 'isoformat'):
                        row_dict[key] = value.isoformat()
                data.append(row_dict)
            
            return {
                "success": True,
                "message": "íˆ¬ì…ë¬¼ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ",
                "data": data,
                "count": len(data)
            }
            
    except Exception as e:
        logger.error(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "íˆ¬ì…ë¬¼ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ì‚°ì¶œë¬¼ ë°ì´í„° ì¡°íšŒ
@app.get("/api/datagather/output-data")
async def get_output_data():
    """ì‚°ì¶œë¬¼ ë°ì´í„° ì¡°íšŒ"""
    try:
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            result = session.execute(text("SELECT * FROM output_data ORDER BY created_at DESC"))
            rows = result.fetchall()
            
            data = []
            for row in rows:
                row_dict = dict(row._mapping)
                for key, value in row_dict.items():
                    if hasattr(value, 'isoformat'):
                        row_dict[key] = value.isoformat()
                data.append(row_dict)
            
            return {
                "success": True,
                "message": "ì‚°ì¶œë¬¼ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ",
                "data": data,
                "count": len(data)
            }
            
    except Exception as e:
        logger.error(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ì‚°ì¶œë¬¼ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ìš´ì†¡ ë°ì´í„° ì¡°íšŒ
@app.get("/api/datagather/transport-data")
async def get_transport_data():
    """ìš´ì†¡ ë°ì´í„° ì¡°íšŒ"""
    try:
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            result = session.execute(text("SELECT * FROM transport_data ORDER BY created_at DESC"))
            rows = result.fetchall()
            
            data = []
            for row in rows:
                row_dict = dict(row._mapping)
                for key, value in row_dict.items():
                    if hasattr(value, 'isoformat'):
                        row_dict[key] = value.isoformat()
                data.append(row_dict)
            
            return {
                "success": True,
                "message": "ìš´ì†¡ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ",
                "data": data,
                "count": len(data)
            }
            
    except Exception as e:
        logger.error(f"ìš´ì†¡ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ìš´ì†¡ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ê³µì • ë°ì´í„° ì¡°íšŒ
@app.get("/api/datagather/process-data")
async def get_process_data():
    """ê³µì • ë°ì´í„° ì¡°íšŒ"""
    try:
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            result = session.execute(text("SELECT * FROM process_data ORDER BY created_at DESC"))
            rows = result.fetchall()
            
            data = []
            for row in rows:
                row_dict = dict(row._mapping)
                for key, value in row_dict.items():
                    if hasattr(value, 'isoformat'):
                        row_dict[key] = value.isoformat()
                data.append(row_dict)
            
            return {
                "success": True,
                "message": "ê³µì • ë°ì´í„° ì¡°íšŒ ì™„ë£Œ",
                "data": data,
                "count": len(data)
            }
            
    except Exception as e:
        logger.error(f"ê³µì • ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ê³µì • ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ì‚°ì¶œë¬¼ ë°ì´í„° ì €ì¥
@app.post("/save-output-data")
async def save_output_data(
    data: Dict[str, Any],

):
    """ì‚°ì¶œë¬¼ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        logger.info(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì €ì¥ ìš”ì²­: {data.get('filename', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        saved_count = 0
        with Session() as session:
            output_data_rows = data.get('data', [])
            
            for row in output_data_rows:
                try:
                    # ì‚°ì¶œë¬¼ëª… í•„ë“œ ë§¤í•‘ ìˆ˜ì •
                    output_name = row.get('ì‚°ì¶œë¬¼ëª…', '') or row.get('íˆ¬ì…ë¬¼ëª…', '')
                    
                    session.execute(text("""
                        INSERT INTO output_data 
                        (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°í’ˆëª…, ìƒì‚°ìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, íˆ¬ì…ì¼, ì¢…ë£Œì¼, 
                         ê³µì •, ì‚°ì¶œë¬¼ëª…, ìˆ˜ëŸ‰, ì‚°ì¶œë¬¼_ë‹¨ìœ„, source_file, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                        VALUES (:ë¡œíŠ¸ë²ˆí˜¸, :ìƒì‚°í’ˆëª…, :ìƒì‚°ìˆ˜ëŸ‰, :ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, :íˆ¬ì…ì¼, :ì¢…ë£Œì¼,
                                :ê³µì •, :ì‚°ì¶œë¬¼ëª…, :ìˆ˜ëŸ‰, :ì‚°ì¶œë¬¼_ë‹¨ìœ„, :source_file, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                    """), {
                        'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                        'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                        'ìƒì‚°ìˆ˜ëŸ‰': float(row.get('ìƒì‚°ìˆ˜ëŸ‰', 0)) if row.get('ìƒì‚°ìˆ˜ëŸ‰') else 0,
                        'ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„': row.get('ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„', 't'),
                        'íˆ¬ì…ì¼': row.get('íˆ¬ì…ì¼'),
                        'ì¢…ë£Œì¼': row.get('ì¢…ë£Œì¼'),
                        'ê³µì •': row.get('ê³µì •', ''),
                        'ì‚°ì¶œë¬¼ëª…': output_name,
                        'ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                        'ì‚°ì¶œë¬¼_ë‹¨ìœ„': row.get('ì‚°ì¶œë¬¼_ë‹¨ìœ„', 't'),
                        'source_file': data.get('filename', 'output_data'),
                        'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                        'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                    })
                    saved_count += 1
                except Exception as row_error:
                    logger.error(f"í–‰ ì €ì¥ ì‹¤íŒ¨: {row_error}, ë°ì´í„°: {row}")
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ê³„ì† ì§„í–‰
                    session.rollback()
                    continue
            
            session.commit()
        
        logger.info(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}í–‰ ì €ì¥ë¨")
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "message": f"ì‚°ì¶œë¬¼ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ({saved_count}í–‰)",
                "saved_count": saved_count,
                "filename": data.get('filename', ''),
                "total_rows": len(output_data_rows)
            }
        )
            
    except Exception as e:
        logger.error(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ì‚°ì¶œë¬¼ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ìš´ì†¡ ë°ì´í„° ì €ì¥
@app.post("/save-transport-data")
async def save_transport_data(
    data: Dict[str, Any],

):
    """ìš´ì†¡ ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        logger.info(f"ìš´ì†¡ ë°ì´í„° ì €ì¥ ìš”ì²­: {data.get('filename', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        saved_count = 0
        with Session() as session:
            transport_data_rows = data.get('data', [])
            
            for row in transport_data_rows:
                try:
                    # Excel í•„ë“œëª… ë§¤í•‘ (ê³µë°± í¬í•¨ í•„ë“œëª… ì‚¬ìš©)
                    transport_material = row.get('ìš´ì†¡ ë¬¼ì§ˆ', '') or row.get('ìš´ì†¡ë¬¼ì§ˆ', '')
                    transport_quantity = row.get('ìš´ì†¡ ìˆ˜ëŸ‰', 0) or row.get('ìš´ì†¡ìˆ˜ëŸ‰', 0)
                    transport_date = row.get('ìš´ì†¡ ì¼ì') or row.get('ìš´ì†¡ì¼ì')
                    destination_process = row.get('ë„ì°© ê³µì •', '') or row.get('ë„ì°©ê³µì •', '')
                    transport_method = row.get('ì´ë™ ìˆ˜ë‹¨', '') or row.get('ì´ë™ìˆ˜ë‹¨', '')
                    
                    # ìš´ì†¡ìˆ˜ëŸ‰ì´ 0ì´ë©´ ê¸°ë³¸ê°’ 1ë¡œ ì„¤ì • (ì²´í¬ ì œì•½ì¡°ê±´ ìœ„ë°˜ ë°©ì§€)
                    if not transport_quantity or float(transport_quantity) <= 0:
                        transport_quantity = 1
                    
                    session.execute(text("""
                        INSERT INTO transport_data 
                        (ìƒì‚°í’ˆëª…, ë¡œíŠ¸ë²ˆí˜¸, ìš´ì†¡ë¬¼ì§ˆ, ìš´ì†¡ìˆ˜ëŸ‰, ìš´ì†¡ì¼ì, 
                         ë„ì°©ê³µì •, ì¶œë°œì§€, ì´ë™ìˆ˜ë‹¨, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                        VALUES (:ìƒì‚°í’ˆëª…, :ë¡œíŠ¸ë²ˆí˜¸, :ìš´ì†¡ë¬¼ì§ˆ, :ìš´ì†¡ìˆ˜ëŸ‰, :ìš´ì†¡ì¼ì,
                                :ë„ì°©ê³µì •, :ì¶œë°œì§€, :ì´ë™ìˆ˜ë‹¨, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                    """), {
                        'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                        'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                        'ìš´ì†¡ë¬¼ì§ˆ': transport_material,
                        'ìš´ì†¡ìˆ˜ëŸ‰': float(transport_quantity),
                        'ìš´ì†¡ì¼ì': transport_date,
                        'ë„ì°©ê³µì •': destination_process,
                        'ì¶œë°œì§€': row.get('ì¶œë°œì§€', ''),
                        'ì´ë™ìˆ˜ë‹¨': transport_method,
                        'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                        'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                    })
                    saved_count += 1
                except Exception as row_error:
                    logger.error(f"í–‰ ì €ì¥ ì‹¤íŒ¨: {row_error}, ë°ì´í„°: {row}")
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ê³„ì† ì§„í–‰
                    session.rollback()
                    continue
            
            session.commit()
        
        logger.info(f"ìš´ì†¡ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}í–‰ ì €ì¥ë¨")
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "message": f"ìš´ì†¡ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ({saved_count}í–‰)",
                "saved_count": saved_count,
                "filename": data.get('filename', ''),
                "total_rows": len(transport_data_rows)
            }
        )
            
    except Exception as e:
        logger.error(f"ìš´ì†¡ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ìš´ì†¡ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ê³µì • ë°ì´í„° ì €ì¥
@app.post("/save-process-data")
async def save_process_data(
    data: Dict[str, Any],

):
    """ê³µì • ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        logger.info(f"ê³µì • ë°ì´í„° ì €ì¥ ìš”ì²­: {data.get('filename', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        saved_count = 0
        with Session() as session:
            process_data_rows = data.get('data', [])
            
            for row in process_data_rows:
                try:
                    # ë””ë²„ê¹…: Excel ë°ì´í„°ì˜ ëª¨ë“  í•„ë“œëª…ê³¼ ê°’ í™•ì¸
                    logger.info(f"Excel ë°ì´í„° í•„ë“œë“¤: {list(row.keys())}")
                    logger.info(f"ì „ì²´ ë°ì´í„°: {row}")
                    logger.info(f"ê³µì •ì„¤ëª… ê°’: '{row.get('ê³µì •ì„¤ëª…', '')}'")
                    logger.info(f"ê³µì • ì„¤ëª… ê°’: '{row.get('ê³µì • ì„¤ëª…', '')}'")
                    
                    # ëª¨ë“  í•„ë“œì˜ ê°’ í™•ì¸ (ë””ë²„ê¹…ìš©)
                    logger.info("=== Excel ë°ì´í„° ëª¨ë“  í•„ë“œ ===")
                    for key, value in row.items():
                        logger.info(f"í•„ë“œ '{key}': '{value}' (íƒ€ì…: {type(value)})")
                    logger.info("=== í•„ë“œ í™•ì¸ ì™„ë£Œ ===")
                    
                    # ê³µì •ì„¤ëª… í•„ë“œ ë§¤í•‘ (ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›)
                    process_description = (
                        row.get('ê³µì • ì„¤ëª…', '') or 
                        row.get('ê³µì •ì„¤ëª…', '') or 
                        row.get('ì„¤ëª…', '') or 
                        row.get('ê³µì •ë‚´ìš©', '') or
                        row.get('ì„¸ë¶€ì„¤ëª…', '') or
                        row.get('ê³µì •_ì„¤ëª…', '') or
                        row.get('ê³µì • ë‚´ìš©', '') or
                        row.get('ì„¸ë¶€ ì„¤ëª…', '') or
                        row.get('process_description', '') or
                        row.get('description', '') or
                        # ê°•ì œë¡œ ìƒì„¸í•œ ì„¤ëª… ìƒì„±
                        f"{row.get('ê³µì •ëª…', '')} ê³µì •: {row.get('ìƒì‚°ì œí’ˆ', '')} ìƒì‚°ì„ ìœ„í•œ {row.get('ì„¸ë¶€ê³µì •', '')} ê³µì •ì…ë‹ˆë‹¤."
                    )
                    
                    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ë” ìƒì„¸í•˜ê²Œ ë§Œë“¤ê¸°
                    if len(process_description) < 10:
                        process_description = f"{row.get('ê³µì •ëª…', '')} ê³µì • - {row.get('ìƒì‚°ì œí’ˆ', '')} ìƒì‚°ì„ ìœ„í•œ {row.get('ì„¸ë¶€ê³µì •', '')} ê³µì •ìœ¼ë¡œ, ì›ë£Œë¥¼ ê°€ê³µí•˜ì—¬ ìµœì¢… ì œí’ˆì„ ìƒì‚°í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
                    
                    logger.info(f"ìµœì¢… ê³µì •ì„¤ëª… ê°’: '{process_description}'")
                    
                    session.execute(text("""
                        INSERT INTO process_data 
                        (ê³µì •ëª…, ìƒì‚°ì œí’ˆ, ì„¸ë¶€ê³µì •, ê³µì •ì„¤ëª…)
                        VALUES (:ê³µì •ëª…, :ìƒì‚°ì œí’ˆ, :ì„¸ë¶€ê³µì •, :ê³µì •ì„¤ëª…)
                    """), {
                        'ê³µì •ëª…': row.get('ê³µì •ëª…', ''),
                        'ìƒì‚°ì œí’ˆ': row.get('ìƒì‚°ì œí’ˆ', ''),
                        'ì„¸ë¶€ê³µì •': row.get('ì„¸ë¶€ê³µì •', ''),
                        'ê³µì •ì„¤ëª…': process_description
                    })
                    saved_count += 1
                except Exception as row_error:
                    logger.error(f"í–‰ ì €ì¥ ì‹¤íŒ¨: {row_error}, ë°ì´í„°: {row}")
                    # íŠ¸ëœì­ì…˜ ë¡¤ë°± í›„ ê³„ì† ì§„í–‰
                    session.rollback()
                    continue
            
            session.commit()
        
        logger.info(f"ê³µì • ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}í–‰ ì €ì¥ë¨")
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "message": f"ê³µì • ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ({saved_count}í–‰)",
                "saved_count": saved_count,
                "filename": data.get('filename', ''),
                "total_rows": len(process_data_rows)
            }
        )
            
    except Exception as e:
        logger.error(f"ê³µì • ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ê³µì • ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ë¥˜ ë° ì €ì¥
@app.post("/save-processed-data")
async def save_processed_data(data: Dict[str, Any]):
    """ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ì—¬ ì ì ˆí•œ í…Œì´ë¸”ì— ì €ì¥"""
    try:
        logger.info(f"ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ë¥˜ ìš”ì²­: {data.get('filename', 'unknown')}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            input_data_rows = data.get('data', [])
            classified_data = {
                'input_data': [],
                'output_data': [],
                'transport_data': [],
                'process_data': [],
                'utility_data': [],
                'waste_data': [],
                'fuel_data': [],
                'process_product_data': []
            }
            
            # ë°ì´í„° ë¶„ë¥˜
            for row in input_data_rows:
                try:
                    # ë¶„ë¥˜ ë¡œì§
                    ë¶„ë¥˜ = row.get('ë¶„ë¥˜', '').lower()
                    íˆ¬ì…ë¬¼ëª… = row.get('íˆ¬ì…ë¬¼ëª…', '').lower()
                    ê³µì • = row.get('ê³µì •', '').lower()
                    
                    if 'ì—°ë£Œ' in ë¶„ë¥˜ or any(fuel in íˆ¬ì…ë¬¼ëª… for fuel in ['ì„íƒ„', 'ê°€ìŠ¤', 'ì˜¤ì¼', 'ì—°ë£Œ', 'fuel']):
                        classified_data['fuel_data'].append(row)
                    elif 'íê¸°ë¬¼' in ë¶„ë¥˜ or any(waste in íˆ¬ì…ë¬¼ëª… for waste in ['íê¸°ë¬¼', 'waste', 'ìŠ¬ë˜ê·¸', 'ì¬']):
                        classified_data['waste_data'].append(row)
                    elif 'ìœ í‹¸ë¦¬í‹°' in ë¶„ë¥˜ or any(util in íˆ¬ì…ë¬¼ëª… for util in ['ì „ê¸°', 'ì¦ê¸°', 'ëƒ‰ê°ìˆ˜', 'utility']):
                        classified_data['utility_data'].append(row)
                    elif 'ì‚°ì¶œë¬¼' in ë¶„ë¥˜ or 'ìƒì‚°í’ˆ' in ë¶„ë¥˜ or any(output in íˆ¬ì…ë¬¼ëª… for output in ['ì œí’ˆ', 'ìƒì‚°í’ˆ', 'ì‚°ì¶œë¬¼']):
                        classified_data['output_data'].append(row)
                    elif 'ìš´ì†¡' in ë¶„ë¥˜ or any(transport in íˆ¬ì…ë¬¼ëª… for transport in ['ìš´ì†¡', 'transport', 'ì´ë™']):
                        classified_data['transport_data'].append(row)
                    elif 'ê³µì •' in ë¶„ë¥˜ or any(process in ê³µì • for process in ['ì œë ¨', 'ì••ì—°', 'ê°€ê³µ', 'ê³µì •']):
                        classified_data['process_product_data'].append(row)
                    else:
                        # ê¸°ë³¸ì ìœ¼ë¡œ íˆ¬ì…ë¬¼ë¡œ ë¶„ë¥˜
                        classified_data['input_data'].append(row)
                
                except Exception as row_error:
                    logger.error(f"í–‰ ë¶„ë¥˜ ì‹¤íŒ¨: {row_error}")
                    continue
            
            # ë¶„ë¥˜ëœ ë°ì´í„°ë¥¼ ê° í…Œì´ë¸”ì— ì €ì¥
            total_saved = 0
            save_results = {}
            
            for table_name, rows in classified_data.items():
                if rows:
                    saved_count = 0
                    for row in rows:
                        try:
                            if table_name == 'input_data':
                                session.execute(text("""
                                    INSERT INTO input_data 
                                    (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°í’ˆëª…, ìƒì‚°ìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, íˆ¬ì…ì¼, ì¢…ë£Œì¼, 
                                     ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, íˆ¬ì…ë¬¼_ë‹¨ìœ„, source_file, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                                    VALUES (:ë¡œíŠ¸ë²ˆí˜¸, :ìƒì‚°í’ˆëª…, :ìƒì‚°ìˆ˜ëŸ‰, :ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, :íˆ¬ì…ì¼, :ì¢…ë£Œì¼,
                                            :ê³µì •, :íˆ¬ì…ë¬¼ëª…, :ìˆ˜ëŸ‰, :íˆ¬ì…ë¬¼_ë‹¨ìœ„, :source_file, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                                """), {
                                    'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                                    'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                                    'ìƒì‚°ìˆ˜ëŸ‰': float(row.get('ìƒì‚°ìˆ˜ëŸ‰', 0)) if row.get('ìƒì‚°ìˆ˜ëŸ‰') else 0,
                                    'ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„': row.get('ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„', 't'),
                                    'íˆ¬ì…ì¼': row.get('íˆ¬ì…ì¼'),
                                    'ì¢…ë£Œì¼': row.get('ì¢…ë£Œì¼'),
                                    'ê³µì •': row.get('ê³µì •', ''),
                                    'íˆ¬ì…ë¬¼ëª…': row.get('íˆ¬ì…ë¬¼ëª…', ''),
                                    'ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                                    'íˆ¬ì…ë¬¼_ë‹¨ìœ„': row.get('íˆ¬ì…ë¬¼_ë‹¨ìœ„', 't'),
                                    'source_file': data.get('filename', 'processed'),
                                    'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                                    'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                                })
                            elif table_name == 'output_data':
                                session.execute(text("""
                                    INSERT INTO output_data 
                                    (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°í’ˆëª…, ìƒì‚°ìˆ˜ëŸ‰, ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, íˆ¬ì…ì¼, ì¢…ë£Œì¼, 
                                     ê³µì •, ì‚°ì¶œë¬¼ëª…, ìˆ˜ëŸ‰, ì‚°ì¶œë¬¼_ë‹¨ìœ„, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                                    VALUES (:ë¡œíŠ¸ë²ˆí˜¸, :ìƒì‚°í’ˆëª…, :ìƒì‚°ìˆ˜ëŸ‰, :ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„, :íˆ¬ì…ì¼, :ì¢…ë£Œì¼,
                                            :ê³µì •, :ì‚°ì¶œë¬¼ëª…, :ìˆ˜ëŸ‰, :ì‚°ì¶œë¬¼_ë‹¨ìœ„, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                                """), {
                                    'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                                    'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                                    'ìƒì‚°ìˆ˜ëŸ‰': float(row.get('ìƒì‚°ìˆ˜ëŸ‰', 0)) if row.get('ìƒì‚°ìˆ˜ëŸ‰') else 0,
                                    'ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„': row.get('ìƒì‚°ìˆ˜ëŸ‰_ë‹¨ìœ„', 't'),
                                    'íˆ¬ì…ì¼': row.get('íˆ¬ì…ì¼'),
                                    'ì¢…ë£Œì¼': row.get('ì¢…ë£Œì¼'),
                                    'ê³µì •': row.get('ê³µì •', ''),
                                    'ì‚°ì¶œë¬¼ëª…': row.get('íˆ¬ì…ë¬¼ëª…', ''),  # ì‚°ì¶œë¬¼ëª…ìœ¼ë¡œ ë§¤í•‘
                                    'ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                                    'ì‚°ì¶œë¬¼_ë‹¨ìœ„': row.get('ì‚°ì¶œë¬¼_ë‹¨ìœ„', 't'),
                                    'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                                    'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                                })
                            elif table_name == 'transport_data':
                                session.execute(text("""
                                    INSERT INTO transport_data 
                                    (ìƒì‚°í’ˆëª…, ë¡œíŠ¸ë²ˆí˜¸, ìš´ì†¡ë¬¼ì§ˆ, ìš´ì†¡ìˆ˜ëŸ‰, ìš´ì†¡ì¼ì, 
                                     ë„ì°©ê³µì •, ì¶œë°œì§€, ì´ë™ìˆ˜ë‹¨, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                                    VALUES (:ìƒì‚°í’ˆëª…, :ë¡œíŠ¸ë²ˆí˜¸, :ìš´ì†¡ë¬¼ì§ˆ, :ìš´ì†¡ìˆ˜ëŸ‰, :ìš´ì†¡ì¼ì,
                                            :ë„ì°©ê³µì •, :ì¶œë°œì§€, :ì´ë™ìˆ˜ë‹¨, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                                """), {
                                    'ìƒì‚°í’ˆëª…': row.get('ìƒì‚°í’ˆëª…', ''),
                                    'ë¡œíŠ¸ë²ˆí˜¸': row.get('ë¡œíŠ¸ë²ˆí˜¸', ''),
                                    'ìš´ì†¡ë¬¼ì§ˆ': row.get('íˆ¬ì…ë¬¼ëª…', ''),
                                    'ìš´ì†¡ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                                    'ìš´ì†¡ì¼ì': row.get('íˆ¬ì…ì¼'),
                                    'ë„ì°©ê³µì •': row.get('ê³µì •', ''),
                                    'ì¶œë°œì§€': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                                    'ì´ë™ìˆ˜ë‹¨': row.get('ë¶„ë¥˜', ''),
                                    'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                                    'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                                })
                            elif table_name == 'process_data':
                                session.execute(text("""
                                    INSERT INTO process_data 
                                    (ê³µì •ëª…, ìƒì‚°ì œí’ˆ, ì„¸ë¶€ê³µì •, ê³µì •ì„¤ëª…)
                                    VALUES (:ê³µì •ëª…, :ìƒì‚°ì œí’ˆ, :ì„¸ë¶€ê³µì •, :ê³µì •ì„¤ëª…)
                                """), {
                                    'ê³µì •ëª…': row.get('ê³µì •', ''),
                                    'ìƒì‚°ì œí’ˆ': row.get('ìƒì‚°í’ˆëª…', ''),
                                    'ì„¸ë¶€ê³µì •': row.get('íˆ¬ì…ë¬¼ëª…', ''),
                                    'ê³µì •ì„¤ëª…': row.get('ë¶„ë¥˜', '')
                                })
                            else:
                                # utility_data, waste_data, fuel_data, process_product_data
                                session.execute(text(f"""
                                    INSERT INTO {table_name} 
                                    (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°ìˆ˜ëŸ‰, íˆ¬ì…ì¼, ì¢…ë£Œì¼, ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, ë‹¨ìœ„, ë¶„ë¥˜, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸)
                                    VALUES (:ë¡œíŠ¸ë²ˆí˜¸, :ìƒì‚°ìˆ˜ëŸ‰, :íˆ¬ì…ì¼, :ì¢…ë£Œì¼, :ê³µì •, :íˆ¬ì…ë¬¼ëª…, :ìˆ˜ëŸ‰, :ë‹¨ìœ„, :ë¶„ë¥˜, :ì£¼ë¬¸ì²˜ëª…, :ì˜¤ë”ë²ˆí˜¸)
                                """), {
                                    'ë¡œíŠ¸ë²ˆí˜¸': int(row.get('ë¡œíŠ¸ë²ˆí˜¸', 0)) if row.get('ë¡œíŠ¸ë²ˆí˜¸') else 0,
                                    'ìƒì‚°ìˆ˜ëŸ‰': float(row.get('ìƒì‚°ìˆ˜ëŸ‰', 0)) if row.get('ìƒì‚°ìˆ˜ëŸ‰') else 0,
                                    'íˆ¬ì…ì¼': row.get('íˆ¬ì…ì¼'),
                                    'ì¢…ë£Œì¼': row.get('ì¢…ë£Œì¼'),
                                    'ê³µì •': row.get('ê³µì •', ''),
                                    'íˆ¬ì…ë¬¼ëª…': row.get('íˆ¬ì…ë¬¼ëª…', ''),
                                    'ìˆ˜ëŸ‰': float(row.get('ìˆ˜ëŸ‰', 0)) if row.get('ìˆ˜ëŸ‰') else 0,
                                    'ë‹¨ìœ„': row.get('ë‹¨ìœ„', 't'),
                                    'ë¶„ë¥˜': row.get('ë¶„ë¥˜', table_name.replace('_data', '')),
                                    'ì£¼ë¬¸ì²˜ëª…': row.get('ì£¼ë¬¸ì²˜ëª…', ''),
                                    'ì˜¤ë”ë²ˆí˜¸': row.get('ì˜¤ë”ë²ˆí˜¸', '')
                                })
                            
                            saved_count += 1
                            total_saved += 1
                        
                        except Exception as row_error:
                            logger.error(f"í–‰ ì €ì¥ ì‹¤íŒ¨ ({table_name}): {row_error}")
                            continue
                    
                    save_results[table_name] = saved_count
                    logger.info(f"{table_name} í…Œì´ë¸”ì— {saved_count}í–‰ ì €ì¥")
            
            session.commit()
            logger.info(f"ë¶„ë¥˜ ë° ì €ì¥ ì™„ë£Œ: ì´ {total_saved}í–‰ ì €ì¥ë¨")
            
            return JSONResponse(
                status_code=200,
                content={
                    "success": True,
                    "message": f"ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¶„ë¥˜ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {total_saved}í–‰)",
                    "total_saved": total_saved,
                    "classification_results": save_results,
                    "filename": data.get('filename', '')
                }
            )
            
    except Exception as e:
        logger.error(f"ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ì²˜ë¦¬ëœ ë°ì´í„° ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ë°ì´í„° ë¶„ë¥˜ ì €ì¥
@app.post("/api/datagather/classify-data")
async def classify_data(data: Dict[str, Any]):
    """ë°ì´í„° ë¶„ë¥˜ ì •ë³´ë¥¼ ë¶„ë¥˜ë³„ í…Œì´ë¸”ì— ì €ì¥"""
    try:
        logger.info(f"ë°ì´í„° ë¶„ë¥˜ ì €ì¥ ìš”ì²­: {data}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        saved_count = 0
        with Session() as session:
            classification_data = data.get('data', [])
            
            for row in classification_data:
                try:
                    ë¶„ë¥˜ = row.get('ë¶„ë¥˜', '').strip()
                    source_table = row.get('source_table', '')
                    source_id = row.get('source_id', 0)
                    
                    # ë¶„ë¥˜ì— ë”°ë¼ ì ì ˆí•œ í…Œì´ë¸”ì— ì €ì¥
                    if ë¶„ë¥˜ == 'ì—°ë£Œ':
                        target_table = 'fuel_data'
                    elif ë¶„ë¥˜ == 'ìœ í‹¸ë¦¬í‹°':
                        target_table = 'utility_data'
                    elif ë¶„ë¥˜ == 'íê¸°ë¬¼':
                        target_table = 'waste_data'
                    elif ë¶„ë¥˜ == 'ê³µì • ìƒì‚°í’ˆ':
                        target_table = 'process_product_data'
                    else:
                        continue
                    
                    # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    existing_check = session.execute(text(f"""
                        SELECT id FROM {target_table} 
                        WHERE source_table = :source_table AND source_id = :source_id
                    """), {
                        'source_table': source_table,
                        'source_id': source_id
                    }).fetchone()
                    
                    if existing_check:
                        # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
                        session.execute(text(f"""
                            UPDATE {target_table} 
                            SET ë¶„ë¥˜ = :ë¶„ë¥˜, updated_at = NOW()
                            WHERE source_table = :source_table AND source_id = :source_id
                        """), {
                            'ë¶„ë¥˜': ë¶„ë¥˜,
                            'source_table': source_table,
                            'source_id': source_id
                        })
                    else:
                        # ê¸°ì¡´ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì‚½ì…
                        if source_table == 'input_data':
                            session.execute(text(f"""
                                INSERT INTO {target_table} 
                                (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°ìˆ˜ëŸ‰, íˆ¬ì…ì¼, ì¢…ë£Œì¼, ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, ë‹¨ìœ„, 
                                 ë¶„ë¥˜, source_table, source_id, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸, created_at)
                                SELECT CAST(ë¡œíŠ¸ë²ˆí˜¸ AS INTEGER), ìƒì‚°ìˆ˜ëŸ‰, íˆ¬ì…ì¼, ì¢…ë£Œì¼, ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, ë‹¨ìœ„,
                                       :ë¶„ë¥˜, :source_table, :source_id, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸, NOW()
                                FROM input_data 
                                WHERE id = :source_id
                            """), {
                                'ë¶„ë¥˜': ë¶„ë¥˜,
                                'source_table': source_table,
                                'source_id': source_id
                            })
                        elif source_table == 'output_data':
                            session.execute(text(f"""
                                INSERT INTO {target_table} 
                                (ë¡œíŠ¸ë²ˆí˜¸, ìƒì‚°ìˆ˜ëŸ‰, íˆ¬ì…ì¼, ì¢…ë£Œì¼, ê³µì •, íˆ¬ì…ë¬¼ëª…, ìˆ˜ëŸ‰, ë‹¨ìœ„, 
                                 ë¶„ë¥˜, source_table, source_id, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸, created_at)
                                SELECT CAST(ë¡œíŠ¸ë²ˆí˜¸ AS INTEGER), ìƒì‚°ìˆ˜ëŸ‰, íˆ¬ì…ì¼, ì¢…ë£Œì¼, ê³µì •, ì‚°ì¶œë¬¼ëª…, ìˆ˜ëŸ‰, ë‹¨ìœ„,
                                       :ë¶„ë¥˜, :source_table, :source_id, ì£¼ë¬¸ì²˜ëª…, ì˜¤ë”ë²ˆí˜¸, NOW()
                                FROM output_data 
                                WHERE id = :source_id
                            """), {
                                'ë¶„ë¥˜': ë¶„ë¥˜,
                                'source_table': source_table,
                                'source_id': source_id
                            })
                    
                    saved_count += 1
                    
                except Exception as row_error:
                    logger.error(f"ë¶„ë¥˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {row_error}, ë°ì´í„°: {row}")
                    session.rollback()
                    continue
            
            session.commit()
        
        logger.info(f"ë¶„ë¥˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {saved_count}í–‰ ì €ì¥ë¨")
        
        return JSONResponse(
            status_code=200,
            content={
                "success": True,
                "message": f"ë¶„ë¥˜ ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ({saved_count}í–‰)",
                "saved_count": saved_count,
                "total_rows": len(classification_data)
            }
        )
            
    except Exception as e:
        logger.error(f"ë¶„ë¥˜ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": "ë¶„ë¥˜ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ë¶„ë¥˜ëœ ë°ì´í„° ì¡°íšŒ
@app.get("/api/datagather/classified-data/{classification}")
async def get_classified_data(classification: str):
    """ë¶„ë¥˜ëœ ë°ì´í„° ì¡°íšŒ (ì—°ë£Œ, ìœ í‹¸ë¦¬í‹°, íê¸°ë¬¼, ê³µì • ìƒì‚°í’ˆ)"""
    try:
        logger.info(f"ë¶„ë¥˜ëœ ë°ì´í„° ì¡°íšŒ ìš”ì²­: {classification}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            # ë¶„ë¥˜ì— ë”°ë¼ ì ì ˆí•œ í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
            if classification == 'ì—°ë£Œ':
                table_name = 'fuel_data'
            elif classification == 'ìœ í‹¸ë¦¬í‹°':
                table_name = 'utility_data'
            elif classification == 'íê¸°ë¬¼':
                table_name = 'waste_data'
            elif classification == 'ê³µì • ìƒì‚°í’ˆ':
                table_name = 'process_product_data'
            else:
                return JSONResponse(
                    status_code=400,
                    content={
                        "success": False,
                        "error": "Invalid classification",
                        "message": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ë¥˜ì…ë‹ˆë‹¤: {classification}"
                    }
                )
            
            # í•´ë‹¹ ë¶„ë¥˜ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¡°íšŒ
            query = f"""
                SELECT 
                    id,
                    ë¡œíŠ¸ë²ˆí˜¸,
                    ìƒì‚°ìˆ˜ëŸ‰,
                    íˆ¬ì…ì¼,
                    ì¢…ë£Œì¼,
                    ê³µì •,
                    íˆ¬ì…ë¬¼ëª…,
                    ìˆ˜ëŸ‰,
                    ë‹¨ìœ„,
                    ë¶„ë¥˜,
                    source_table,
                    source_id,
                    ì£¼ë¬¸ì²˜ëª…,
                    ì˜¤ë”ë²ˆí˜¸,
                    created_at,
                    updated_at
                FROM {table_name}
                ORDER BY created_at DESC
            """
            
            result = session.execute(text(query))
            rows = result.fetchall()
            
            data = []
            for row in rows:
                row_dict = dict(row._mapping)
                
                # ë‚ ì§œ í•„ë“œ ì²˜ë¦¬
                for key, value in row_dict.items():
                    if hasattr(value, 'isoformat'):
                        row_dict[key] = value.isoformat()
                
                data.append(row_dict)
            
            logger.info(f"ë¶„ë¥˜ëœ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(data)}í–‰ ({classification})")
            
            return {
                "success": True,
                "message": f"{classification} ë¶„ë¥˜ ë°ì´í„° ì¡°íšŒ ì™„ë£Œ",
                "data": data,
                "count": len(data),
                "classification": classification
            }
            
    except Exception as e:
        logger.error(f"ë¶„ë¥˜ëœ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": f"{classification} ë¶„ë¥˜ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

# ë°ì´í„° ì‚­ì œ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.delete("/api/datagather/input-data/{data_id}")
async def delete_input_data(data_id: int):
    """íˆ¬ì…ë¬¼ ë°ì´í„° ì‚­ì œ"""
    try:
        logger.info(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì‚­ì œ ìš”ì²­: ID {data_id}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            check_query = "SELECT id FROM input_data WHERE id = :data_id"
            result = session.execute(text(check_query), {"data_id": data_id})
            if not result.fetchone():
                return JSONResponse(
                    status_code=404,
                    content={
                        "success": False,
                        "error": "Data not found",
                        "message": f"ID {data_id}ì— í•´ë‹¹í•˜ëŠ” íˆ¬ì…ë¬¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    }
                )
            
            # ë°ì´í„° ì‚­ì œ
            delete_query = "DELETE FROM input_data WHERE id = :data_id"
            session.execute(text(delete_query), {"data_id": data_id})
            session.commit()
            
            logger.info(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: ID {data_id}")
            
            return {
                "success": True,
                "message": f"íˆ¬ì…ë¬¼ ë°ì´í„° (ID: {data_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "deleted_id": data_id
            }
            
    except Exception as e:
        logger.error(f"íˆ¬ì…ë¬¼ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": f"íˆ¬ì…ë¬¼ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

@app.delete("/api/datagather/output-data/{data_id}")
async def delete_output_data(data_id: int):
    """ì‚°ì¶œë¬¼ ë°ì´í„° ì‚­ì œ"""
    try:
        logger.info(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì‚­ì œ ìš”ì²­: ID {data_id}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            check_query = "SELECT id FROM output_data WHERE id = :data_id"
            result = session.execute(text(check_query), {"data_id": data_id})
            if not result.fetchone():
                return JSONResponse(
                    status_code=404,
                    content={
                        "success": False,
                        "error": "Data not found",
                        "message": f"ID {data_id}ì— í•´ë‹¹í•˜ëŠ” ì‚°ì¶œë¬¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    }
                )
            
            # ë°ì´í„° ì‚­ì œ
            delete_query = "DELETE FROM output_data WHERE id = :data_id"
            session.execute(text(delete_query), {"data_id": data_id})
            session.commit()
            
            logger.info(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: ID {data_id}")
            
            return {
                "success": True,
                "message": f"ì‚°ì¶œë¬¼ ë°ì´í„° (ID: {data_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "deleted_id": data_id
            }
            
    except Exception as e:
        logger.error(f"ì‚°ì¶œë¬¼ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": f"ì‚°ì¶œë¬¼ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

@app.delete("/api/datagather/transport-data/{data_id}")
async def delete_transport_data(data_id: int):
    """ìš´ì†¡ ë°ì´í„° ì‚­ì œ"""
    try:
        logger.info(f"ìš´ì†¡ ë°ì´í„° ì‚­ì œ ìš”ì²­: ID {data_id}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            check_query = "SELECT id FROM transport_data WHERE id = :data_id"
            result = session.execute(text(check_query), {"data_id": data_id})
            if not result.fetchone():
                return JSONResponse(
                    status_code=404,
                    content={
                        "success": False,
                        "error": "Data not found",
                        "message": f"ID {data_id}ì— í•´ë‹¹í•˜ëŠ” ìš´ì†¡ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    }
                )
            
            # ë°ì´í„° ì‚­ì œ
            delete_query = "DELETE FROM transport_data WHERE id = :data_id"
            session.execute(text(delete_query), {"data_id": data_id})
            session.commit()
            
            logger.info(f"ìš´ì†¡ ë°ì´í„° ì‚­ì œ ì™„ë£Œ: ID {data_id}")
            
            return {
                "success": True,
                "message": f"ìš´ì†¡ ë°ì´í„° (ID: {data_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "deleted_id": data_id
            }
            
    except Exception as e:
        logger.error(f"ìš´ì†¡ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": f"ìš´ì†¡ ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

@app.delete("/api/datagather/process-data/{data_id}")
async def delete_process_data(data_id: int):
    """ê³µì • ë°ì´í„° ì‚­ì œ"""
    try:
        logger.info(f"ê³µì • ë°ì´í„° ì‚­ì œ ìš”ì²­: ID {data_id}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        from sqlalchemy import create_engine, text
        from sqlalchemy.orm import sessionmaker
        
        engine = create_engine(settings.database_url.replace("postgresql+asyncpg://", "postgresql://"))
        Session = sessionmaker(bind=engine)
        
        with Session() as session:
            # ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            check_query = "SELECT id FROM process_data WHERE id = :data_id"
            result = session.execute(text(check_query), {"data_id": data_id})
            if not result.fetchone():
                return JSONResponse(
                    status_code=404,
                    content={
                        "success": False,
                        "error": "Data not found",
                        "message": f"ID {data_id}ì— í•´ë‹¹í•˜ëŠ” ê³µì • ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    }
                )
            
            # ë°ì´í„° ì‚­ì œ
            delete_query = "DELETE FROM process_data WHERE id = :data_id"
            session.execute(text(delete_query), {"data_id": data_id})
            session.commit()
            
            logger.info(f"ê³µì • ë°ì´í„° ì‚­ì œ ì™„ë£Œ: ID {data_id}")
            
            return {
                "success": True,
                "message": f"ê³µì • ë°ì´í„° (ID: {data_id})ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "deleted_id": data_id
            }
            
    except Exception as e:
        logger.error(f"ê³µì • ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": str(e),
                "message": f"ê³µì • ë°ì´í„° ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }
        )

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host=settings.host,
        port=settings.port,
        reload=settings.debug,
        log_level=settings.log_level.lower()
    )